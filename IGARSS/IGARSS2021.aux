\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{Zhu2017_Deep}
\citation{Murphy2012_Machine}
\citation{ehsan2017infinite}
\citation{makhzani2015adversarial}
\citation{tian2014learning}
\citation{song2013auto}
\citation{xie2016unsupervised}
\citation{jiang2017variational}
\citation{yang2018geodesic}
\providecommand \oddpage@label [2]{}
\@writefile{toc}{\contentsline {section}{\numberline {1} Introduction}{1}{section.1}}
\newlabel{sec:Introduction}{{1}{1}{Introduction}{section.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2} Background}{1}{section.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1} Variational Autoencoder Networks (VAEs)}{1}{subsection.2.1}}
\citation{Murphy2019_Unsupervised}
\citation{Maggioni2019_LUND}
\citation{Murphy2019_Spectral}
\citation{Maggioni2019_LAND}
\citation{Maggioni2019_LAND}
\citation{Murphy2019_Unsupervised}
\citation{Maggioni2019_LAND}
\citation{pourkamali2019effectiveness}
\citation{pourkamali2019effectiveness}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2} Learning by Active Nonlinear Diffusion}{2}{subsection.2.2}}
\newlabel{eqn:rho}{{1}{2}{Learning by Active Nonlinear Diffusion}{equation.2.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3} Proposed Algorithm}{2}{section.3}}
\newlabel{sec:ProposedAlgorithm}{{3}{2}{Proposed Algorithm}{section.3}{}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{alg:VALAND}{{1}{3}{Proposed Algorithm}{algocf.1}{}}
\@writefile{loa}{\contentsline {algocf}{\numberline {1}{\ignorespaces Variational Autoencoder Learning by Active Nonlinear Diffusion (VALAND)\relax }}{3}{algocf.1}}
\@writefile{toc}{\contentsline {section}{\numberline {4} Experimental Results}{3}{section.4}}
\newlabel{sec:Experiments}{{4}{3}{Experimental Results}{section.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces \relax \fontsize  {9}{11}\selectfont  \abovedisplayskip 8.5\p@ plus3\p@ minus4\p@ \abovedisplayshortskip \z@ plus2\p@ \belowdisplayshortskip 4\p@ plus2\p@ minus2\p@ \def \leftmargin \leftmargini \parsep 4\p@ plus2\p@ minus\p@ \topsep 8\p@ plus2\p@ minus4\p@ \itemsep 4\p@ plus2\p@ minus\p@ {\leftmargin \leftmargini \topsep 4\p@ plus2\p@ minus2\p@ \parsep 2\p@ plus\p@ minus\p@ \itemsep \parsep }\belowdisplayskip \abovedisplayskip {The $86\times 83$ Salinas A HSI data consists of 6 classes. Left: the sum of all spectral bands. Right: the ground truth.}\relax }}{3}{figure.caption.2}}
\newlabel{fig:SalinasA}{{1}{3}{\small {The $86\times 83$ Salinas A HSI data consists of 6 classes. Left: the sum of all spectral bands. Right: the ground truth.}\relax }{figure.caption.2}{}}
\bibstyle{IEEEbib}
\bibdata{IGARSS2021_ref}
\bibcite{Zhu2017_Deep}{1}
\bibcite{Murphy2012_Machine}{2}
\bibcite{ehsan2017infinite}{3}
\bibcite{makhzani2015adversarial}{4}
\bibcite{tian2014learning}{5}
\bibcite{song2013auto}{6}
\bibcite{xie2016unsupervised}{7}
\bibcite{jiang2017variational}{8}
\bibcite{yang2018geodesic}{9}
\bibcite{Murphy2019_Unsupervised}{10}
\bibcite{Maggioni2019_LUND}{11}
\bibcite{Murphy2019_Spectral}{12}
\bibcite{Maggioni2019_LAND}{13}
\bibcite{pourkamali2019effectiveness}{14}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces For the Salinas A dataset, the performance of variational autoencoder LAND learning achieves a higher accuracy than the standard LAND algorithm. With just $10$ points, the overall accuracy of VAE-LAND is 96.97\%, a 12.5\% improvement to the competitive LAND algorithm. {\leavevmode {\color  {blue}[Asymptotics?]}}\relax }}{4}{figure.caption.3}}
\newlabel{fig:my_label}{{2}{4}{For the Salinas A dataset, the performance of variational autoencoder LAND learning achieves a higher accuracy than the standard LAND algorithm. With just $10$ points, the overall accuracy of VAE-LAND is 96.97\%, a 12.5\% improvement to the competitive LAND algorithm. \JMM {Asymptotics?}\relax }{figure.caption.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1} Discussion of Experimental Results}{4}{subsection.4.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2} Computational Complexity}{4}{subsection.4.2}}
\@writefile{toc}{\contentsline {section}{\numberline {5} Conclusions and Future Directions}{4}{section.5}}
\newlabel{sec:Conclusions}{{5}{4}{Conclusions and Future Directions}{section.5}{}}
\@writefile{toc}{\contentsline {section}{\numberline {6} References}{4}{section.6}}
